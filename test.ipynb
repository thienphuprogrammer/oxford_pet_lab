{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07f964a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import OxfordPetDatasetLoader\n",
    "from src.config import Config\n",
    "from src.data import DataPreprocessor, DataAugmentor\n",
    "\n",
    "\n",
    "config = Config()\n",
    "config.USE_IMAGENET_NORM = True          # For transfer learning\n",
    "config.PRESERVE_ASPECT_RATIO = True      # Better image quality\n",
    "config.ENABLE_QUALITY_ENHANCEMENT = True # Image enhancement\n",
    "config.NORMALIZATION_METHOD = 'imagenet' # Best for pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3942e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.dataset_loader:Initialized Oxford Pet Dataset Loader\n",
      "INFO:src.data.dataset_loader:Data directory: ./data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = OxfordPetDatasetLoader(\n",
    "    data_dir=\"./data\",  # Tùy chọn\n",
    "    download=True,\n",
    "    log_level='INFO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9812d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.dataset_loader:Creating train/validation/test splits...\n",
      "INFO:src.data.dataset_loader:Checking dataset availability...\n",
      "INFO:absl:Load dataset info from data/oxford_iiit_pet/4.0.0\n",
      "INFO:src.data.dataset_loader:Dataset already available.\n",
      "INFO:src.data.dataset_loader:Loading raw dataset splits: ['train', 'test']\n",
      "INFO:absl:Load dataset info from data/oxford_iiit_pet/4.0.0\n",
      "INFO:absl:Creating a tf.data.Dataset reading 4 files located in folders: data/oxford_iiit_pet/4.0.0.\n",
      "INFO:absl:Creating a tf.data.Dataset reading 4 files located in folders: data/oxford_iiit_pet/4.0.0.\n",
      "INFO:absl:Constructing tf.data.Dataset oxford_iiit_pet for split ['train', 'test'], from data/oxford_iiit_pet/4.0.0\n",
      "INFO:src.data.dataset_loader:Train set: 3,680 examples\n",
      "INFO:src.data.dataset_loader:Test set: 3,669 examples\n",
      "INFO:src.data.dataset_loader:Split sizes - Train: 2,944, Val: 736, Test: 3,669\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds, val_ds, test_ds = loader.create_train_val_test_splits(\n",
    "    val_split=0.2,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a53329a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'head_bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None),\n",
       " 'label': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None),\n",
       " 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bdba002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = DataAugmentor(\n",
    "    config=config,\n",
    "    prob_geo=0.7,\n",
    "    prob_photo=0.8,\n",
    "    prob_mixup=0.3,\n",
    "    prob_cutout=0.2,\n",
    "    prob_mosaic=0.3,\n",
    ")\n",
    "\n",
    "train_ds = augmentor.create_augmented_dataset(\n",
    "    train_ds,\n",
    "    augmentation_factor=3\n",
    ")\n",
    "\n",
    "val_ds = augmentor.create_augmented_dataset(\n",
    "    val_ds,\n",
    "    augmentation_factor=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "91b41f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': TensorSpec(shape=(512, 512, 3), dtype=tf.float32, name=None),\n",
       " 'head_bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'segmentation_mask': TensorSpec(shape=(512, 512, 1), dtype=tf.float32, name=None),\n",
       " 'label': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " 'species': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " 'file_name': TensorSpec(shape=(), dtype=tf.string, name=None)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "56514ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = DataPreprocessor(\n",
    "    config=Config(),\n",
    "    shuffle_buffer=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "91debd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset element spec:\n",
      "{'image': TensorSpec(shape=(512, 512, 3), dtype=tf.float32, name=None), 'head_bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None), 'segmentation_mask': TensorSpec(shape=(512, 512, 1), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None), 'file_name': TensorSpec(shape=(), dtype=tf.string, name=None)}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-16 17:32:11.750445: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n",
      "2025-06-16 17:32:20.885561: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:452] fused(ShuffleDatasetV3:22,RepeatDataset:23): Filling up shuffle buffer (this may take a while): 3487 of 5000\n",
      "2025-06-16 17:32:24.863618: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:482] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample element type: <class 'dict'>\n",
      "Sample keys: ['image', 'head_bbox', 'segmentation_mask', 'label', 'species', 'file_name']\n",
      "Dataset element spec after preprocessing:\n",
      "(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), {'bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None), 'pet_class': TensorSpec(shape=(), dtype=tf.int32, name=None), 'species': TensorSpec(shape=(), dtype=tf.int32, name=None), 'valid_bbox': TensorSpec(shape=(), dtype=tf.bool, name=None), 'area': TensorSpec(shape=(), dtype=tf.float32, name=None)})\n",
      "Original dataset element spec:\n",
      "{'image': TensorSpec(shape=(512, 512, 3), dtype=tf.float32, name=None), 'head_bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None), 'segmentation_mask': TensorSpec(shape=(512, 512, 1), dtype=tf.float32, name=None), 'label': TensorSpec(shape=(), dtype=tf.int64, name=None), 'species': TensorSpec(shape=(), dtype=tf.int64, name=None), 'file_name': TensorSpec(shape=(), dtype=tf.string, name=None)}\n",
      "Sample element type: <class 'dict'>\n",
      "Sample keys: ['image', 'head_bbox', 'segmentation_mask', 'label', 'species', 'file_name']\n",
      "Dataset element spec after preprocessing:\n",
      "(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None), {'bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None), 'pet_class': TensorSpec(shape=(), dtype=tf.int32, name=None), 'species': TensorSpec(shape=(), dtype=tf.int32, name=None), 'valid_bbox': TensorSpec(shape=(), dtype=tf.bool, name=None), 'area': TensorSpec(shape=(), dtype=tf.float32, name=None)})\n"
     ]
    }
   ],
   "source": [
    "train_ds = processor.create_training_dataset(\n",
    "    train_ds,\n",
    "    batch_size=8,\n",
    "    task=\"detection\",\n",
    "    cache_filename=\"train_cache\"  # File caching for speed\n",
    ")\n",
    "\n",
    "val_ds = processor.create_validation_dataset(\n",
    "    val_ds,\n",
    "    batch_size=8,\n",
    "    task=\"detection\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
