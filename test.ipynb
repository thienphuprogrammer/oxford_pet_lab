{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "07f964a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import OxfordPetDatasetLoader\n",
    "from src.config import Config\n",
    "from src.data import DataPreprocessor, DataAugmentor\n",
    "\n",
    "\n",
    "config = Config()\n",
    "config.USE_IMAGENET_NORM = True          # For transfer learning\n",
    "config.PRESERVE_ASPECT_RATIO = True      # Better image quality\n",
    "config.ENABLE_QUALITY_ENHANCEMENT = True # Image enhancement\n",
    "config.NORMALIZATION_METHOD = 'imagenet' # Best for pretrained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae3942e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.dataset_loader:Initialized Oxford Pet Dataset Loader\n",
      "INFO:src.data.dataset_loader:Data directory: ./data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "loader = OxfordPetDatasetLoader(\n",
    "    data_dir=\"./data\",  # Tùy chọn\n",
    "    download=True,\n",
    "    log_level='INFO'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9812d2ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:src.data.dataset_loader:Creating train/validation/test splits...\n",
      "INFO:src.data.dataset_loader:Checking dataset availability...\n",
      "INFO:absl:Load dataset info from data/oxford_iiit_pet/4.0.0\n",
      "INFO:src.data.dataset_loader:Dataset already available.\n",
      "INFO:src.data.dataset_loader:Loading raw dataset splits: ['train', 'test']\n",
      "INFO:absl:Load dataset info from data/oxford_iiit_pet/4.0.0\n",
      "INFO:absl:Creating a tf.data.Dataset reading 4 files located in folders: data/oxford_iiit_pet/4.0.0.\n",
      "INFO:absl:Creating a tf.data.Dataset reading 4 files located in folders: data/oxford_iiit_pet/4.0.0.\n",
      "INFO:absl:Constructing tf.data.Dataset oxford_iiit_pet for split ['train', 'test'], from data/oxford_iiit_pet/4.0.0\n",
      "INFO:src.data.dataset_loader:Train set: 3,680 examples\n",
      "INFO:src.data.dataset_loader:Test set: 3,669 examples\n",
      "INFO:src.data.dataset_loader:Split sizes - Train: 2,944, Val: 736, Test: 3,669\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_ds, val_ds, test_ds = loader.create_train_val_test_splits(\n",
    "    val_split=0.2,\n",
    "    seed=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bebc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a53329a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'file_name': TensorSpec(shape=(), dtype=tf.string, name=None),\n",
       " 'head_bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       " 'image': TensorSpec(shape=(None, None, 3), dtype=tf.uint8, name=None),\n",
       " 'label': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       " 'segmentation_mask': TensorSpec(shape=(None, None, 1), dtype=tf.uint8, name=None),\n",
       " 'species': TensorSpec(shape=(), dtype=tf.int64, name=None)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdba002f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "preprocessor = DataPreprocessor(config=cfg)\n",
    "train_ds = train_ds.map(preprocessor.preprocess_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(preprocessor.preprocess_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(preprocessor.preprocess_sample, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "augmentor = DataAugmentor(config=cfg, target_height=cfg.IMG_SIZE[0], target_width=cfg.IMG_SIZE[1])\n",
    "train_ds = train_ds.map(augmentor, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2bad4e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_detection(sample):\n",
    "    image = sample['image']\n",
    "    target = {\n",
    "        'bbox': sample['head_bbox'],\n",
    "        'label': sample['label'],\n",
    "        'species': sample['species'],\n",
    "            }\n",
    "    return image, target\n",
    "    \n",
    "output_signature = (\n",
    "            tf.TensorSpec(shape=(cfg.IMG_SIZE[0], cfg.IMG_SIZE[1], 3), dtype=tf.float32),\n",
    "            {\n",
    "                'bbox': tf.TensorSpec(shape=(4,), dtype=tf.float32),\n",
    "                'label': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
    "                'species': tf.TensorSpec(shape=(), dtype=tf.int64),\n",
    "            }\n",
    "        )\n",
    "train_ds = train_ds.map(format_detection, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "val_ds = val_ds.map(format_detection, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "test_ds = test_ds.map(format_detection, num_parallel_calls=tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91b41f49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorSpec(shape=(224, 224, 3), dtype=tf.float32, name=None),\n",
       " {'bbox': TensorSpec(shape=(4,), dtype=tf.float32, name=None),\n",
       "  'label': TensorSpec(shape=(), dtype=tf.int64, name=None),\n",
       "  'species': TensorSpec(shape=(), dtype=tf.int64, name=None)})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.element_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "347b74b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(224, 224, 3), dtype=float32, numpy=\n",
       " array([[[-1.058022  ,  3.2451658 ,  4.184864  ],\n",
       "         [-0.63337547,  3.6889808 ,  4.6247435 ],\n",
       "         [-0.5866383 ,  3.737828  ,  4.673157  ],\n",
       "         ...,\n",
       "         [-5.665044  , -5.946573  , -5.3901305 ],\n",
       "         [-6.129087  , -6.546707  , -5.946902  ],\n",
       "         [-6.52969   , -7.084718  , -6.440719  ]],\n",
       " \n",
       "        [[-0.36763743,  3.966716  ,  4.900014  ],\n",
       "         [ 0.02506831,  4.377149  ,  5.306808  ],\n",
       "         [-0.01225097,  4.282506  ,  5.2130036 ],\n",
       "         ...,\n",
       "         [-4.90237   , -5.1037893 , -4.4149256 ],\n",
       "         [-5.3748207 , -5.727349  , -4.971697  ],\n",
       "         [-5.839305  , -6.231978  , -5.465514  ]],\n",
       " \n",
       "        [[ 0.03831434,  4.276551  ,  5.320529  ],\n",
       "         [ 0.42490277,  4.68059   ,  5.7209854 ],\n",
       "         [ 0.37148815,  4.607006  ,  5.6480546 ],\n",
       "         ...,\n",
       "         [-4.912265  , -4.9909406 , -4.2195754 ],\n",
       "         [-5.3398867 , -5.570451  , -4.728241  ],\n",
       "         [-5.7711415 , -6.0211725 , -5.174966  ]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[-1.1835486 , -0.07508016,  0.3725734 ],\n",
       "         [-1.2735074 , -0.16910103,  0.27938646],\n",
       "         [-1.3468341 , -0.24573664,  0.2034292 ],\n",
       "         ...,\n",
       "         [-1.9039786 , -0.4526032 ,  0.67481744],\n",
       "         [-1.9407023 , -0.4909846 ,  0.71285844],\n",
       "         [-1.9787593 , -0.5307594 ,  0.7522807 ]],\n",
       " \n",
       "        [[-0.89370084,  0.05618523,  0.5593887 ],\n",
       "         [-0.9297221 ,  0.01853798,  0.52207536],\n",
       "         [-0.91362673,  0.03535992,  0.53874826],\n",
       "         ...,\n",
       "         [-1.8046708 , -0.34881288,  0.77768713],\n",
       "         [-1.8193977 , -0.36420473,  0.83851403],\n",
       "         [-1.8352442 , -0.38076657,  0.90094316]],\n",
       " \n",
       "        [[-0.8096445 ,  0.14403608,  0.6464605 ],\n",
       "         [-0.7094915 ,  0.24871008,  0.75020593],\n",
       "         [-0.6093385 ,  0.35338408,  0.85395163],\n",
       "         ...,\n",
       "         [-1.8579069 , -0.40445235,  0.72254115],\n",
       "         [-1.757754  , -0.29977837,  0.90237   ],\n",
       "         [-1.6576034 , -0.19510674,  1.0849565 ]]], dtype=float32)>,\n",
       " {'bbox': <tf.Tensor: shape=(4,), dtype=float32, numpy=array([0.06      , 0.39333335, 0.55      , 0.69666666], dtype=float32)>,\n",
       "  'label': <tf.Tensor: shape=(), dtype=int64, numpy=36>,\n",
       "  'species': <tf.Tensor: shape=(), dtype=int64, numpy=1>})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the sample\n",
    "sample = next(iter(train_ds))\n",
    "sample\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
